ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.11.3: Fast Qwen3 patching. Transformers: 4.57.1. vLLM: 0.11.2.
   \\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.9.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.5.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
*** length Dataset:  431
<class 'list'>
#### reasoning example:  <|im_start|>user
You are a helpful system for identifying multiple-word expressions (MWEs). Identify all MWEs in the given sentence, and output their surface forms. Each sentence is a string of words delimited by'\n'. An MWE is defined as a sequence that satisfies the following three conditions. 1. It consists of multiple words that are always realized by the same lexemes. The individual lexemes cannot be replaced by synonyms without distorting the meaning of the expression as a whole or violating language conventions. 2. It displays semantic, lexical, or syntactic idiomaticity. Semantic idiomaticity occurs when the meaning of an expression cannot be explicitly derived from its components. Lexical idiomaticity occurs when one or more components of an expression are not used as stand-alone words in standard English. Syntactic idiomaticity occurs when the grammar of an expression cannot be derived directly from that of its components. For example, semantically idiomatic MWEs include 'break up', the lexically idiomatic include 'to and fro', and syntactically idiomatic MWEs include 'long time no see'. 3. It is not a multi-word named entity, i.e., a specific name of a person, facility, etc.
 Remember that you can identify congruent MWEs across different languages. For example, you can identify the Romanian MWE 'pur »ôi simplu' because you know the English MWE 'pure and simple'. Similarly, the Portuguese MWE 'ter lugar' is easy to identify because of the English MWE 'take place'. And the French MWE 'feu de circulation' is easy to identify, because it is almost congruent to the English MWE 'traffic lights'. Respond by providing all tokens of the MWE, and their indices. If no MWE occurs, output 'None'. If there are multiple MWEs, separate them by |, for example 'to and fro; 7,8,9 |¬†break up; 12, 13'. Sentence: ·∏•kn ‚∏óƒç m Íú•n·∏´ m Íú£w.t-ÍûΩb<|im_end|>
<|im_start|>assistant
<think>
Okay, let's tackle this query. The user wants me to identify all multiple-word expressions (MWEs) in the given sentence. The sentence is split into words by newlines, so first I need to parse each line as a token. Let me list them out with their indices to keep track. The words are:
1 ·∏•kn
2 ‚∏óƒç
3 m
4 Íú•n·∏´
5 m
6-7(a contracted form consisting of the two following lemmas) Íú£w.t-ÍûΩb
6 Íú£w.t
7 ÍûΩb
Now we apply the MWE criteria. The first condition is that the expression consists of multiple words that are always realized by the same lexemes. The individual lexemes cannot be replaced by synonyms without distorting the meaning of the expression as a whole or violating language conventions. The second condition is that it displays semantic, lexical, or syntactic idiomaticity. Semantic idiomaticity occurs when the meaning of an expression cannot be explicitly derived from its components. Lexical idiomaticity occurs when one or more components of an expression are not used as stand-alone words in standard English. Syntactic idiomaticity occurs when the grammar of an expression cannot be derived directly from that of its components. For example, semantically idiomatic MWEs include 'break up', the lexically idiomatic include 'to and fro', and syntactically idiomatic MWEs include 'long time no see'. The third condition is that it is not a multi-word named entity. Looking at the words, let's check for possible MWEs.  Íú£w.t ÍûΩb is a multiword expression. More precisely, it is a NV.VID, i.e. a nominal phrase (N) that is derived from a verbal expression (V), where the verbal expression is a verbal idiom or VID. An example similar to the current one is the English NV.VID "a heart breaker", which derives from the VID "to break one's heart". The words cannot be realized by synonymous lexemes without altering the meaning of the construction as a whole, which satisfies condition 1. The given expression fulfills condition 2, as it is lexically idiomatic: it takes on a meaning that is unique to this combination of words. The expression does not refer to a specific person or place, so it also meets condition 3.
After considering all possibilities, my final answer is: Íú£w.t ÍûΩb; 6,7
</think>

Íú£w.t ÍûΩb; 6,7<|im_end|>

#### reasoning length:  431
###############Length combined dataset:  431
made it
GPU = NVIDIA H100 PCIe. Max memory = 79.109 GB.
30.119 GB of memory reserved.
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 1.6423, 'grad_norm': 0.3839060962200165, 'learning_rate': 0.0, 'epoch': 0.01}
{'loss': 1.6596, 'grad_norm': 0.34776028990745544, 'learning_rate': 4e-05, 'epoch': 0.02}
{'loss': 1.6335, 'grad_norm': 0.34133610129356384, 'learning_rate': 8e-05, 'epoch': 0.03}
{'loss': 1.6173, 'grad_norm': 0.45313215255737305, 'learning_rate': 0.00012, 'epoch': 0.04}
{'loss': 1.5048, 'grad_norm': 0.5195560455322266, 'learning_rate': 0.00016, 'epoch': 0.05}
{'loss': 1.3375, 'grad_norm': 0.5585395693778992, 'learning_rate': 0.0002, 'epoch': 0.06}
{'loss': 1.0677, 'grad_norm': 0.5630940198898315, 'learning_rate': 0.0001990521327014218, 'epoch': 0.06}
{'loss': 1.0211, 'grad_norm': 0.5026686191558838, 'learning_rate': 0.0001981042654028436, 'epoch': 0.07}
{'loss': 0.7789, 'grad_norm': 0.5418955683708191, 'learning_rate': 0.0001971563981042654, 'epoch': 0.08}
{'loss': 0.6231, 'grad_norm': 0.8512369394302368, 'learning_rate': 0.0001962085308056872, 'epoch': 0.09}
{'loss': 0.4912, 'grad_norm': 0.5832927823066711, 'learning_rate': 0.000195260663507109, 'epoch': 0.1}
{'loss': 0.3696, 'grad_norm': 0.7604407072067261, 'learning_rate': 0.00019431279620853083, 'epoch': 0.11}
{'loss': 0.3145, 'grad_norm': 0.44018587470054626, 'learning_rate': 0.0001933649289099526, 'epoch': 0.12}
{'loss': 0.3201, 'grad_norm': 0.2581634819507599, 'learning_rate': 0.00019241706161137443, 'epoch': 0.13}
{'loss': 0.2478, 'grad_norm': 0.5094923377037048, 'learning_rate': 0.0001914691943127962, 'epoch': 0.14}
{'loss': 0.2673, 'grad_norm': 0.3033161461353302, 'learning_rate': 0.000190521327014218, 'epoch': 0.15}
{'loss': 0.2212, 'grad_norm': 0.23619550466537476, 'learning_rate': 0.00018957345971563983, 'epoch': 0.16}
{'loss': 0.2507, 'grad_norm': 0.47202929854393005, 'learning_rate': 0.0001886255924170616, 'epoch': 0.17}
{'loss': 0.1968, 'grad_norm': 0.16442938148975372, 'learning_rate': 0.00018767772511848343, 'epoch': 0.18}
{'loss': 0.2801, 'grad_norm': 0.20126651227474213, 'learning_rate': 0.00018672985781990523, 'epoch': 0.19}
{'loss': 0.1781, 'grad_norm': 0.18555738031864166, 'learning_rate': 0.00018578199052132703, 'epoch': 0.19}
{'loss': 0.1938, 'grad_norm': 0.17801491916179657, 'learning_rate': 0.00018483412322274883, 'epoch': 0.2}
{'loss': 0.1751, 'grad_norm': 0.20306287705898285, 'learning_rate': 0.0001838862559241706, 'epoch': 0.21}
{'loss': 0.2304, 'grad_norm': 0.2119806557893753, 'learning_rate': 0.00018293838862559243, 'epoch': 0.22}
{'loss': 0.1885, 'grad_norm': 0.23239532113075256, 'learning_rate': 0.00018199052132701423, 'epoch': 0.23}
{'loss': 0.1749, 'grad_norm': 0.2002321481704712, 'learning_rate': 0.00018104265402843603, 'epoch': 0.24}
{'loss': 0.3041, 'grad_norm': 0.2603876292705536, 'learning_rate': 0.00018009478672985783, 'epoch': 0.25}
{'loss': 0.2428, 'grad_norm': 0.24535860121250153, 'learning_rate': 0.00017914691943127963, 'epoch': 0.26}
{'loss': 0.1396, 'grad_norm': 0.20223790407180786, 'learning_rate': 0.00017819905213270143, 'epoch': 0.27}
{'loss': 0.1674, 'grad_norm': 0.16758207976818085, 'learning_rate': 0.00017725118483412323, 'epoch': 0.28}
{'loss': 0.2222, 'grad_norm': 0.24760474264621735, 'learning_rate': 0.00017630331753554503, 'epoch': 0.29}
{'loss': 0.1922, 'grad_norm': 0.2636805474758148, 'learning_rate': 0.00017535545023696683, 'epoch': 0.3}
{'loss': 0.1135, 'grad_norm': 0.21378426253795624, 'learning_rate': 0.00017440758293838863, 'epoch': 0.31}
{'loss': 0.2185, 'grad_norm': 0.2793937027454376, 'learning_rate': 0.00017345971563981043, 'epoch': 0.32}
{'loss': 0.2042, 'grad_norm': 0.3361070156097412, 'learning_rate': 0.00017251184834123225, 'epoch': 0.32}
{'loss': 0.1482, 'grad_norm': 0.19300363957881927, 'learning_rate': 0.00017156398104265403, 'epoch': 0.33}
{'loss': 0.1588, 'grad_norm': 0.24138331413269043, 'learning_rate': 0.00017061611374407585, 'epoch': 0.34}
{'loss': 0.093, 'grad_norm': 0.16757310926914215, 'learning_rate': 0.00016966824644549762, 'epoch': 0.35}
{'loss': 0.1127, 'grad_norm': 0.2361641526222229, 'learning_rate': 0.00016872037914691945, 'epoch': 0.36}
{'loss': 0.1724, 'grad_norm': 0.19241997599601746, 'learning_rate': 0.00016777251184834125, 'epoch': 0.37}
{'loss': 0.1017, 'grad_norm': 0.17590749263763428, 'learning_rate': 0.00016682464454976302, 'epoch': 0.38}
{'loss': 0.1763, 'grad_norm': 0.20868481695652008, 'learning_rate': 0.00016587677725118485, 'epoch': 0.39}
{'loss': 0.0977, 'grad_norm': 0.154778853058815, 'learning_rate': 0.00016492890995260665, 'epoch': 0.4}
{'loss': 0.1353, 'grad_norm': 0.16363941133022308, 'learning_rate': 0.00016398104265402845, 'epoch': 0.41}
{'loss': 0.1408, 'grad_norm': 0.2888854146003723, 'learning_rate': 0.00016303317535545025, 'epoch': 0.42}
{'loss': 0.0883, 'grad_norm': 0.5912545919418335, 'learning_rate': 0.00016208530805687205, 'epoch': 0.43}
{'loss': 0.0959, 'grad_norm': 0.17380638420581818, 'learning_rate': 0.00016113744075829385, 'epoch': 0.44}
{'loss': 0.1312, 'grad_norm': 0.15084148943424225, 'learning_rate': 0.00016018957345971565, 'epoch': 0.45}
{'loss': 0.1022, 'grad_norm': 0.17607860267162323, 'learning_rate': 0.00015924170616113745, 'epoch': 0.45}
{'loss': 0.1127, 'grad_norm': 0.18332436680793762, 'learning_rate': 0.00015829383886255925, 'epoch': 0.46}
{'loss': 0.1923, 'grad_norm': 0.2004081755876541, 'learning_rate': 0.00015734597156398105, 'epoch': 0.47}
{'loss': 0.0881, 'grad_norm': 0.15580028295516968, 'learning_rate': 0.00015639810426540285, 'epoch': 0.48}
{'loss': 0.0633, 'grad_norm': 0.11843796074390411, 'learning_rate': 0.00015545023696682465, 'epoch': 0.49}
{'loss': 0.09, 'grad_norm': 0.1896226853132248, 'learning_rate': 0.00015450236966824645, 'epoch': 0.5}
{'loss': 0.093, 'grad_norm': 0.1471182405948639, 'learning_rate': 0.00015355450236966827, 'epoch': 0.51}
{'loss': 0.1123, 'grad_norm': 0.16881676018238068, 'learning_rate': 0.00015260663507109004, 'epoch': 0.52}
{'loss': 0.1131, 'grad_norm': 0.17751993238925934, 'learning_rate': 0.00015165876777251184, 'epoch': 0.53}
{'loss': 0.1052, 'grad_norm': 0.17132794857025146, 'learning_rate': 0.00015071090047393367, 'epoch': 0.54}
{'loss': 0.1349, 'grad_norm': 0.223551943898201, 'learning_rate': 0.00014976303317535544, 'epoch': 0.55}
{'loss': 0.0694, 'grad_norm': 0.1321144700050354, 'learning_rate': 0.00014881516587677727, 'epoch': 0.56}
{'loss': 0.1314, 'grad_norm': 0.21215197443962097, 'learning_rate': 0.00014786729857819904, 'epoch': 0.57}
{'loss': 0.1493, 'grad_norm': 0.21303409337997437, 'learning_rate': 0.00014691943127962087, 'epoch': 0.58}
{'loss': 0.0805, 'grad_norm': 0.1921854466199875, 'learning_rate': 0.00014597156398104267, 'epoch': 0.58}
{'loss': 0.0963, 'grad_norm': 0.1617850959300995, 'learning_rate': 0.00014502369668246447, 'epoch': 0.59}
{'loss': 0.1102, 'grad_norm': 0.17574018239974976, 'learning_rate': 0.00014407582938388627, 'epoch': 0.6}
{'loss': 0.1081, 'grad_norm': 0.17669111490249634, 'learning_rate': 0.00014312796208530804, 'epoch': 0.61}
{'loss': 0.1477, 'grad_norm': 0.1988004893064499, 'learning_rate': 0.00014218009478672987, 'epoch': 0.62}
{'loss': 0.1548, 'grad_norm': 0.20131994783878326, 'learning_rate': 0.00014123222748815167, 'epoch': 0.63}
{'loss': 0.0911, 'grad_norm': 0.1613045185804367, 'learning_rate': 0.00014028436018957347, 'epoch': 0.64}
{'loss': 0.1316, 'grad_norm': 0.16471584141254425, 'learning_rate': 0.00013933649289099527, 'epoch': 0.65}
{'loss': 0.0829, 'grad_norm': 0.14463423192501068, 'learning_rate': 0.00013838862559241707, 'epoch': 0.66}
{'loss': 0.0922, 'grad_norm': 0.13148947060108185, 'learning_rate': 0.00013744075829383887, 'epoch': 0.67}
{'loss': 0.1107, 'grad_norm': 0.15998642146587372, 'learning_rate': 0.0001364928909952607, 'epoch': 0.68}
{'loss': 0.1037, 'grad_norm': 0.18427932262420654, 'learning_rate': 0.00013554502369668246, 'epoch': 0.69}
{'loss': 0.0743, 'grad_norm': 0.11806248873472214, 'learning_rate': 0.00013459715639810426, 'epoch': 0.7}
{'loss': 0.0792, 'grad_norm': 0.13186094164848328, 'learning_rate': 0.00013364928909952606, 'epoch': 0.71}
{'loss': 0.0678, 'grad_norm': 0.1110820323228836, 'learning_rate': 0.00013270142180094786, 'epoch': 0.71}
{'loss': 0.1204, 'grad_norm': 0.1766422539949417, 'learning_rate': 0.0001317535545023697, 'epoch': 0.72}
{'loss': 0.1065, 'grad_norm': 0.16287463903427124, 'learning_rate': 0.00013080568720379146, 'epoch': 0.73}
{'loss': 0.0502, 'grad_norm': 0.11066459119319916, 'learning_rate': 0.0001298578199052133, 'epoch': 0.74}
{'loss': 0.0733, 'grad_norm': 0.13647881150245667, 'learning_rate': 0.0001289099526066351, 'epoch': 0.75}
{'loss': 0.0713, 'grad_norm': 0.1785622537136078, 'learning_rate': 0.00012796208530805686, 'epoch': 0.76}
{'loss': 0.1034, 'grad_norm': 0.18270887434482574, 'learning_rate': 0.0001270142180094787, 'epoch': 0.77}
{'loss': 0.1282, 'grad_norm': 0.1842527687549591, 'learning_rate': 0.00012606635071090046, 'epoch': 0.78}
{'loss': 0.109, 'grad_norm': 0.18775597214698792, 'learning_rate': 0.0001251184834123223, 'epoch': 0.79}
{'loss': 0.0615, 'grad_norm': 0.14801397919654846, 'learning_rate': 0.0001241706161137441, 'epoch': 0.8}
{'loss': 0.1047, 'grad_norm': 0.14873892068862915, 'learning_rate': 0.0001232227488151659, 'epoch': 0.81}
{'loss': 0.1103, 'grad_norm': 0.14760564267635345, 'learning_rate': 0.0001222748815165877, 'epoch': 0.82}
{'loss': 0.1106, 'grad_norm': 0.16686248779296875, 'learning_rate': 0.0001213270142180095, 'epoch': 0.83}
{'loss': 0.0753, 'grad_norm': 0.1364533007144928, 'learning_rate': 0.00012037914691943129, 'epoch': 0.84}
{'loss': 0.0852, 'grad_norm': 0.14652612805366516, 'learning_rate': 0.00011943127962085307, 'epoch': 0.84}
{'loss': 0.0918, 'grad_norm': 0.1934048980474472, 'learning_rate': 0.00011848341232227489, 'epoch': 0.85}
{'loss': 0.1072, 'grad_norm': 0.17208744585514069, 'learning_rate': 0.00011753554502369668, 'epoch': 0.86}
{'loss': 0.1018, 'grad_norm': 0.1481674313545227, 'learning_rate': 0.0001165876777251185, 'epoch': 0.87}
{'loss': 0.0891, 'grad_norm': 0.1623155027627945, 'learning_rate': 0.00011563981042654028, 'epoch': 0.88}
{'loss': 0.08, 'grad_norm': 0.11176209896802902, 'learning_rate': 0.0001146919431279621, 'epoch': 0.89}
{'loss': 0.1442, 'grad_norm': 0.19489964842796326, 'learning_rate': 0.00011374407582938388, 'epoch': 0.9}
{'loss': 0.1323, 'grad_norm': 0.1733357161283493, 'learning_rate': 0.0001127962085308057, 'epoch': 0.91}
{'loss': 0.0859, 'grad_norm': 0.12898938357830048, 'learning_rate': 0.0001118483412322275, 'epoch': 0.92}
{'loss': 0.0703, 'grad_norm': 0.11852317303419113, 'learning_rate': 0.00011090047393364928, 'epoch': 0.93}
{'loss': 0.0728, 'grad_norm': 0.10748644173145294, 'learning_rate': 0.0001099526066350711, 'epoch': 0.94}
{'loss': 0.0662, 'grad_norm': 0.1278066635131836, 'learning_rate': 0.0001090047393364929, 'epoch': 0.95}
{'loss': 0.0616, 'grad_norm': 0.17832116782665253, 'learning_rate': 0.00010805687203791471, 'epoch': 0.96}
{'loss': 0.1053, 'grad_norm': 0.18917371332645416, 'learning_rate': 0.0001071090047393365, 'epoch': 0.97}
{'loss': 0.064, 'grad_norm': 0.11841931939125061, 'learning_rate': 0.00010616113744075831, 'epoch': 0.97}
{'loss': 0.0494, 'grad_norm': 0.12684960663318634, 'learning_rate': 0.0001052132701421801, 'epoch': 0.98}
{'loss': 0.1579, 'grad_norm': 0.26029083132743835, 'learning_rate': 0.0001042654028436019, 'epoch': 0.99}
{'loss': 0.2196, 'grad_norm': 0.3069459795951843, 'learning_rate': 0.0001033175355450237, 'epoch': 1.0}
{'loss': 0.0855, 'grad_norm': 0.189010351896286, 'learning_rate': 0.00010236966824644549, 'epoch': 1.01}
{'loss': 0.1093, 'grad_norm': 0.18629871308803558, 'learning_rate': 0.0001014218009478673, 'epoch': 1.02}
{'loss': 0.085, 'grad_norm': 0.12999816238880157, 'learning_rate': 0.00010047393364928909, 'epoch': 1.03}
{'loss': 0.0837, 'grad_norm': 0.14338602125644684, 'learning_rate': 9.95260663507109e-05, 'epoch': 1.04}
{'loss': 0.1499, 'grad_norm': 0.1817380040884018, 'learning_rate': 9.85781990521327e-05, 'epoch': 1.05}
{'loss': 0.0816, 'grad_norm': 0.12769465148448944, 'learning_rate': 9.76303317535545e-05, 'epoch': 1.06}
{'loss': 0.0867, 'grad_norm': 0.16267786920070648, 'learning_rate': 9.66824644549763e-05, 'epoch': 1.06}
{'loss': 0.1051, 'grad_norm': 0.18200957775115967, 'learning_rate': 9.57345971563981e-05, 'epoch': 1.07}
{'loss': 0.1008, 'grad_norm': 0.15248338878154755, 'learning_rate': 9.478672985781992e-05, 'epoch': 1.08}
{'loss': 0.124, 'grad_norm': 0.15905682742595673, 'learning_rate': 9.383886255924172e-05, 'epoch': 1.09}
{'loss': 0.0667, 'grad_norm': 0.1681661307811737, 'learning_rate': 9.289099526066352e-05, 'epoch': 1.1}
{'loss': 0.0687, 'grad_norm': 0.13982824981212616, 'learning_rate': 9.19431279620853e-05, 'epoch': 1.11}
{'loss': 0.1288, 'grad_norm': 0.2075881063938141, 'learning_rate': 9.099526066350711e-05, 'epoch': 1.12}
{'loss': 0.0706, 'grad_norm': 0.1300368458032608, 'learning_rate': 9.004739336492891e-05, 'epoch': 1.13}
{'loss': 0.0555, 'grad_norm': 0.15380489826202393, 'learning_rate': 8.909952606635071e-05, 'epoch': 1.14}
{'loss': 0.1271, 'grad_norm': 0.21196529269218445, 'learning_rate': 8.815165876777251e-05, 'epoch': 1.15}
{'loss': 0.1309, 'grad_norm': 0.2056812196969986, 'learning_rate': 8.720379146919431e-05, 'epoch': 1.16}
{'loss': 0.0779, 'grad_norm': 0.15607939660549164, 'learning_rate': 8.625592417061613e-05, 'epoch': 1.17}
{'loss': 0.058, 'grad_norm': 0.13990874588489532, 'learning_rate': 8.530805687203793e-05, 'epoch': 1.18}
{'loss': 0.033, 'grad_norm': 0.11723625659942627, 'learning_rate': 8.436018957345973e-05, 'epoch': 1.19}
{'loss': 0.0518, 'grad_norm': 0.14126166701316833, 'learning_rate': 8.341232227488151e-05, 'epoch': 1.19}
{'loss': 0.0835, 'grad_norm': 0.15936650335788727, 'learning_rate': 8.246445497630332e-05, 'epoch': 1.2}
{'loss': 0.0797, 'grad_norm': 0.1800636202096939, 'learning_rate': 8.151658767772512e-05, 'epoch': 1.21}
{'loss': 0.0704, 'grad_norm': 0.15702074766159058, 'learning_rate': 8.056872037914692e-05, 'epoch': 1.22}
{'loss': 0.0945, 'grad_norm': 0.17445792257785797, 'learning_rate': 7.962085308056872e-05, 'epoch': 1.23}
{'loss': 0.0494, 'grad_norm': 0.13873377442359924, 'learning_rate': 7.867298578199052e-05, 'epoch': 1.24}
{'loss': 0.0658, 'grad_norm': 0.1575898379087448, 'learning_rate': 7.772511848341232e-05, 'epoch': 1.25}
{'loss': 0.1551, 'grad_norm': 0.23971149325370789, 'learning_rate': 7.677725118483414e-05, 'epoch': 1.26}
{'loss': 0.0697, 'grad_norm': 0.15102818608283997, 'learning_rate': 7.582938388625592e-05, 'epoch': 1.27}
{'loss': 0.0709, 'grad_norm': 0.15174831449985504, 'learning_rate': 7.488151658767772e-05, 'epoch': 1.28}
{'loss': 0.0632, 'grad_norm': 0.15623365342617035, 'learning_rate': 7.393364928909952e-05, 'epoch': 1.29}
{'loss': 0.0626, 'grad_norm': 0.12923555076122284, 'learning_rate': 7.298578199052133e-05, 'epoch': 1.3}
{'loss': 0.0701, 'grad_norm': 0.14628784358501434, 'learning_rate': 7.203791469194313e-05, 'epoch': 1.31}
{'loss': 0.0891, 'grad_norm': 0.1556473821401596, 'learning_rate': 7.109004739336493e-05, 'epoch': 1.32}
{'loss': 0.0733, 'grad_norm': 0.12414450943470001, 'learning_rate': 7.014218009478673e-05, 'epoch': 1.32}
{'loss': 0.0922, 'grad_norm': 0.1583385318517685, 'learning_rate': 6.919431279620853e-05, 'epoch': 1.33}
{'loss': 0.0865, 'grad_norm': 0.15693074464797974, 'learning_rate': 6.824644549763035e-05, 'epoch': 1.34}
{'loss': 0.0848, 'grad_norm': 0.1699810028076172, 'learning_rate': 6.729857819905213e-05, 'epoch': 1.35}
{'loss': 0.0633, 'grad_norm': 0.14089809358119965, 'learning_rate': 6.635071090047393e-05, 'epoch': 1.36}
{'loss': 0.055, 'grad_norm': 0.12019487470388412, 'learning_rate': 6.540284360189573e-05, 'epoch': 1.37}
{'loss': 0.0462, 'grad_norm': 0.12135956436395645, 'learning_rate': 6.445497630331754e-05, 'epoch': 1.38}
{'loss': 0.0772, 'grad_norm': 0.1405687928199768, 'learning_rate': 6.350710900473934e-05, 'epoch': 1.39}
{'loss': 0.0771, 'grad_norm': 0.1588640660047531, 'learning_rate': 6.255924170616114e-05, 'epoch': 1.4}
{'loss': 0.075, 'grad_norm': 0.17451037466526031, 'learning_rate': 6.161137440758294e-05, 'epoch': 1.41}
{'loss': 0.1107, 'grad_norm': 0.2410164475440979, 'learning_rate': 6.066350710900475e-05, 'epoch': 1.42}
{'loss': 0.0509, 'grad_norm': 0.15745210647583008, 'learning_rate': 5.9715639810426536e-05, 'epoch': 1.43}
{'loss': 0.0659, 'grad_norm': 0.19394046068191528, 'learning_rate': 5.876777251184834e-05, 'epoch': 1.44}
{'loss': 0.1317, 'grad_norm': 0.2643871605396271, 'learning_rate': 5.781990521327014e-05, 'epoch': 1.45}
{'loss': 0.0432, 'grad_norm': 0.12788638472557068, 'learning_rate': 5.687203791469194e-05, 'epoch': 1.45}
{'loss': 0.0826, 'grad_norm': 0.161235511302948, 'learning_rate': 5.592417061611375e-05, 'epoch': 1.46}
{'loss': 0.0701, 'grad_norm': 0.1548561304807663, 'learning_rate': 5.497630331753555e-05, 'epoch': 1.47}
{'loss': 0.0925, 'grad_norm': 0.1797243058681488, 'learning_rate': 5.4028436018957354e-05, 'epoch': 1.48}
{'loss': 0.0491, 'grad_norm': 0.15847712755203247, 'learning_rate': 5.3080568720379154e-05, 'epoch': 1.49}
{'loss': 0.0615, 'grad_norm': 0.16125766932964325, 'learning_rate': 5.213270142180095e-05, 'epoch': 1.5}
{'loss': 0.0627, 'grad_norm': 0.15698732435703278, 'learning_rate': 5.1184834123222746e-05, 'epoch': 1.51}
{'loss': 0.0618, 'grad_norm': 0.1570272594690323, 'learning_rate': 5.0236966824644546e-05, 'epoch': 1.52}
{'loss': 0.0534, 'grad_norm': 0.12752622365951538, 'learning_rate': 4.928909952606635e-05, 'epoch': 1.53}
{'loss': 0.0876, 'grad_norm': 0.17257051169872284, 'learning_rate': 4.834123222748815e-05, 'epoch': 1.54}
{'loss': 0.0513, 'grad_norm': 0.1390524059534073, 'learning_rate': 4.739336492890996e-05, 'epoch': 1.55}
{'loss': 0.1122, 'grad_norm': 0.19255849719047546, 'learning_rate': 4.644549763033176e-05, 'epoch': 1.56}
{'loss': 0.1056, 'grad_norm': 0.1829969584941864, 'learning_rate': 4.549763033175356e-05, 'epoch': 1.57}
{'loss': 0.0904, 'grad_norm': 0.17436081171035767, 'learning_rate': 4.454976303317536e-05, 'epoch': 1.58}
{'loss': 0.1016, 'grad_norm': 0.24196328222751617, 'learning_rate': 4.3601895734597157e-05, 'epoch': 1.58}
{'loss': 0.0712, 'grad_norm': 0.15843860805034637, 'learning_rate': 4.265402843601896e-05, 'epoch': 1.59}
{'loss': 0.0881, 'grad_norm': 0.1685112863779068, 'learning_rate': 4.1706161137440756e-05, 'epoch': 1.6}
{'loss': 0.0567, 'grad_norm': 0.15439283847808838, 'learning_rate': 4.075829383886256e-05, 'epoch': 1.61}
{'loss': 0.063, 'grad_norm': 0.15875859558582306, 'learning_rate': 3.981042654028436e-05, 'epoch': 1.62}
{'loss': 0.0494, 'grad_norm': 0.17363274097442627, 'learning_rate': 3.886255924170616e-05, 'epoch': 1.63}
{'loss': 0.1176, 'grad_norm': 0.20176570117473602, 'learning_rate': 3.791469194312796e-05, 'epoch': 1.64}
{'loss': 0.0589, 'grad_norm': 0.1588578075170517, 'learning_rate': 3.696682464454976e-05, 'epoch': 1.65}
{'loss': 0.0495, 'grad_norm': 0.13933761417865753, 'learning_rate': 3.601895734597157e-05, 'epoch': 1.66}
{'loss': 0.059, 'grad_norm': 0.1680823117494583, 'learning_rate': 3.507109004739337e-05, 'epoch': 1.67}
{'loss': 0.0638, 'grad_norm': 0.19431819021701813, 'learning_rate': 3.412322274881517e-05, 'epoch': 1.68}
{'loss': 0.0692, 'grad_norm': 0.15289628505706787, 'learning_rate': 3.3175355450236966e-05, 'epoch': 1.69}
{'loss': 0.0571, 'grad_norm': 0.15770255029201508, 'learning_rate': 3.222748815165877e-05, 'epoch': 1.7}
{'loss': 0.0528, 'grad_norm': 0.12366556376218796, 'learning_rate': 3.127962085308057e-05, 'epoch': 1.71}
{'loss': 0.0491, 'grad_norm': 0.177883580327034, 'learning_rate': 3.0331753554502375e-05, 'epoch': 1.71}
{'loss': 0.0541, 'grad_norm': 0.1718297153711319, 'learning_rate': 2.938388625592417e-05, 'epoch': 1.72}
{'loss': 0.0322, 'grad_norm': 0.11712690442800522, 'learning_rate': 2.843601895734597e-05, 'epoch': 1.73}
{'loss': 0.0505, 'grad_norm': 0.16068266332149506, 'learning_rate': 2.7488151658767774e-05, 'epoch': 1.74}
{'loss': 0.1074, 'grad_norm': 0.2502084970474243, 'learning_rate': 2.6540284360189577e-05, 'epoch': 1.75}
{'loss': 0.0966, 'grad_norm': 0.21442312002182007, 'learning_rate': 2.5592417061611373e-05, 'epoch': 1.76}
{'loss': 0.0689, 'grad_norm': 0.16687779128551483, 'learning_rate': 2.4644549763033176e-05, 'epoch': 1.77}
{'loss': 0.0734, 'grad_norm': 0.1971592903137207, 'learning_rate': 2.369668246445498e-05, 'epoch': 1.78}
{'loss': 0.0725, 'grad_norm': 0.25975099205970764, 'learning_rate': 2.274881516587678e-05, 'epoch': 1.79}
{'loss': 0.0781, 'grad_norm': 0.17854338884353638, 'learning_rate': 2.1800947867298578e-05, 'epoch': 1.8}
{'loss': 0.0636, 'grad_norm': 0.21211427450180054, 'learning_rate': 2.0853080568720378e-05, 'epoch': 1.81}
{'loss': 0.0636, 'grad_norm': 0.16806143522262573, 'learning_rate': 1.990521327014218e-05, 'epoch': 1.82}
{'loss': 0.0627, 'grad_norm': 0.17203389108181, 'learning_rate': 1.895734597156398e-05, 'epoch': 1.83}
{'loss': 0.0714, 'grad_norm': 0.15604574978351593, 'learning_rate': 1.8009478672985784e-05, 'epoch': 1.84}
{'loss': 0.0478, 'grad_norm': 0.12501415610313416, 'learning_rate': 1.7061611374407587e-05, 'epoch': 1.84}
{'loss': 0.0736, 'grad_norm': 0.17294184863567352, 'learning_rate': 1.6113744075829386e-05, 'epoch': 1.85}
{'loss': 0.1395, 'grad_norm': 0.2696000635623932, 'learning_rate': 1.5165876777251187e-05, 'epoch': 1.86}
{'loss': 0.0653, 'grad_norm': 0.22159677743911743, 'learning_rate': 1.4218009478672985e-05, 'epoch': 1.87}
{'loss': 0.0945, 'grad_norm': 0.19437959790229797, 'learning_rate': 1.3270142180094788e-05, 'epoch': 1.88}
{'loss': 0.1007, 'grad_norm': 0.3449375033378601, 'learning_rate': 1.2322274881516588e-05, 'epoch': 1.89}
{'loss': 0.0908, 'grad_norm': 0.18692903220653534, 'learning_rate': 1.137440758293839e-05, 'epoch': 1.9}
{'loss': 0.0464, 'grad_norm': 0.12856361269950867, 'learning_rate': 1.0426540284360189e-05, 'epoch': 1.91}
{'loss': 0.075, 'grad_norm': 0.1578054279088974, 'learning_rate': 9.47867298578199e-06, 'epoch': 1.92}
{'loss': 0.1145, 'grad_norm': 0.1958789825439453, 'learning_rate': 8.530805687203793e-06, 'epoch': 1.93}
{'loss': 0.1081, 'grad_norm': 0.19955025613307953, 'learning_rate': 7.582938388625594e-06, 'epoch': 1.94}
{'loss': 0.1087, 'grad_norm': 0.18666762113571167, 'learning_rate': 6.635071090047394e-06, 'epoch': 1.95}
{'loss': 0.0983, 'grad_norm': 0.17657087743282318, 'learning_rate': 5.687203791469195e-06, 'epoch': 1.96}
{'loss': 0.05, 'grad_norm': 0.13350579142570496, 'learning_rate': 4.739336492890995e-06, 'epoch': 1.97}
{'loss': 0.0836, 'grad_norm': 0.18382801115512848, 'learning_rate': 3.791469194312797e-06, 'epoch': 1.97}
{'loss': 0.0803, 'grad_norm': 0.17324627935886383, 'learning_rate': 2.8436018957345973e-06, 'epoch': 1.98}
{'loss': 0.0973, 'grad_norm': 0.1846349686384201, 'learning_rate': 1.8957345971563984e-06, 'epoch': 1.99}
{'loss': 0.1004, 'grad_norm': 0.20402628183364868, 'learning_rate': 9.478672985781992e-07, 'epoch': 2.0}
{'train_runtime': 711.5459, 'train_samples_per_second': 1.211, 'train_steps_per_second': 0.304, 'train_loss': 0.16220116177228866, 'epoch': 2.0}
711.5459 seconds used for training.
11.86 minutes used for training.
Peak reserved memory = 30.119 GB.
Peak reserved memory for training = 0.0 GB.
Peak reserved memory % of max memory = 38.073 %.
Peak reserved memory for training % of max memory = 0.0 %.

Slurm Job Summary
*****************
- General information:
    date = Wed Dec 3 17:07:21 CET 2025
    hostname = nesh-gpu01
- Job information:
    JobId = 19407594
    JobName = EGY_finetuning
    UserId = sunpn1133(820286)
    Account = sunpn1133
    QOS = normal
    NodeList = nesh-gpu01
    Features = H100
    Command = /gxfs_work/cau/sunpn1133/parseme_2_0/job_finetuning_EGY.sh
    WorkDir = /gxfs_work/cau/sunpn1133/parseme_2_0
    StdOut = /gxfs_work/cau/sunpn1133/parseme_2_0/test_train_EGY.out
    StdErr = /gxfs_work/cau/sunpn1133/parseme_2_0/test_train_EGY.err
- Requested resources:
    Timelimit = 03:00:00 ( 10800s )
    MinMemoryNode = 80G ( 81920.000M )
    NumNodes = 1
    NumCPUs = 2
    NumTasks = 1
    CPUs/Task = 2
- Used resources:
    RunTime = 00:16:43 ( 1003s )
    MaxRSS = 6096252K ( 5953.371M )
====================
- Important conclusions and remarks:
    * !!! Please, always check if the number of requested cores and nodes matches the need of your program/code !!!
    * !!! Less than 10% of requested walltime used !!! Consider adaptation of your batch script.
    * !!! Less than 10% of requested main memory used !!! Consider adaptation of your batch script.

