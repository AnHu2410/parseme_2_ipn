INFO 12-05 09:12:41 [utils.py:253] non-default args: {'max_model_len': 5000, 'gpu_memory_utilization': 0.85, 'disable_log_stats': True, 'enforce_eager': True, 'enable_lora': True, 'model': '../Qwen3-32B-INT8'}
INFO 12-05 09:12:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-05 09:12:41 [model.py:1745] Using max model len 5000
INFO 12-05 09:12:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 12-05 09:12:47 [vllm.py:500] Cudagraph is disabled under eager mode
WARNING 12-05 09:12:48 [system_utils.py:103] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:13:57 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='../Qwen3-32B-INT8', speculative_config=None, tokenizer='../Qwen3-32B-INT8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=../Qwen3-32B-INT8, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': None, 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 0, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://0.0.0.0:52955 backend=nccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:04 [gpu_model_runner.py:3259] Starting to load model ../Qwen3-32B-INT8...
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:04 [compressed_tensors_w8a8_int8.py:62] Using CutlassScaledMMLinearKernel for CompressedTensorsW8A8Int8
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:17 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:17 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:43 [default_loader.py:314] Loading weights took 25.59 seconds
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:43 [punica_selector.py:20] Using PunicaWrapperGPU.
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:44 [gpu_model_runner.py:3338] Model loading took 32.3027 GiB memory and 38.901792 seconds
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:46 [gpu_worker.py:359] Available KV cache memory: 29.09 GiB
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:46 [kv_cache_utils.py:1229] GPU KV cache size: 119,152 tokens
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:46 [kv_cache_utils.py:1234] Maximum concurrency for 5,000 tokens per request: 23.79x
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:46 [core.py:250] init engine (profile, create kv cache, warmup model) took 2.86 seconds
[1;36m(EngineCore_DP0 pid=3538682)[0;0m INFO 12-05 09:14:47 [vllm.py:500] Cudagraph is disabled under eager mode
INFO 12-05 09:14:47 [llm.py:352] Supported tasks: ['generate']
WARNING 12-05 09:14:48 [processor.py:246] vLLM has deprecated support for supporting different tokenizers for different LoRAs. By default, vLLM uses base model's tokenizer. If you are using a LoRA with its own tokenizer, consider specifying `--tokenizer [lora_path]` to use the LoRA tokenizer.
[1;36m(EngineCore_DP0 pid=3538682)[0;0m WARNING 12-05 09:14:49 [utils.py:250] Using default LoRA kernel configs
####PRED#### å½“åˆ ã‹ã‚‰ ãƒã‚¦ ã‚’ æ°— ã« å…¥ã£ ã¦ã„ã‚‹ ã€ æš´åŠ›å›£ ã® å¨˜ ã€‚	æ°— ã« å…¥ã£; 5, 6, 7

list##### ['å½“åˆ ã‹ã‚‰ ãƒã‚¦ ã‚’ æ°— ã« å…¥ã£ ã¦ã„ã‚‹ ã€ æš´åŠ›å›£ ã® å¨˜ ã€‚', 'æ°— ã« å…¥ã£; 5, 6, 7\n']
####PRED#### åˆ©ç”¨æ—¥ ã® 1ã‹æœˆå‰ ã‹ã‚‰ å½“æ—¥ ã¾ã§ ç™ºå£² ã€‚	1ã‹æœˆå‰; 3 | ã‹ã‚‰ ã¾ã§; 4, 6 | ç™ºå£²; 7

list##### ['åˆ©ç”¨æ—¥ ã® 1ã‹æœˆå‰ ã‹ã‚‰ å½“æ—¥ ã¾ã§ ç™ºå£² ã€‚', '1ã‹æœˆå‰; 3 | ã‹ã‚‰ ã¾ã§; 4, 6 | ç™ºå£²; 7\n']
####PRED#### ãƒ‡ã‚¶ã‚¤ãƒ³ ã‚‚ è‰¯ã„ ã— , ç§‹ ã® å¤œé•· ã« ãƒ”ãƒƒã‚¿ãƒª ãª ã‚µã‚¤ãƒˆ ã  ã¨ æ€ã„ ã¾ã™ ã€‚	ç§‹ ã® å¤œé•·; 6,7,8 | ãƒ”ãƒƒã‚¿ãƒª ãª; 10,11 | æ€ã„ ã¾ã™; 15,16

list##### ['ãƒ‡ã‚¶ã‚¤ãƒ³ ã‚‚ è‰¯ã„ ã— , ç§‹ ã® å¤œé•· ã« ãƒ”ãƒƒã‚¿ãƒª ãª ã‚µã‚¤ãƒˆ ã  ã¨ æ€ã„ ã¾ã™ ã€‚', 'ç§‹ ã® å¤œé•·; 6,7,8 | ãƒ”ãƒƒã‚¿ãƒª ãª; 10,11 | æ€ã„ ã¾ã™; 15,16\n']
####PRED#### ã‚ã„ã‚ã„ æ¥½ã—ã ã‚„ã‚‹ ã¨ã ã« ãŠã™ã™ã‚ ã€‚	None

list##### ['ã‚ã„ã‚ã„ æ¥½ã—ã ã‚„ã‚‹ ã¨ã ã« ãŠã™ã™ã‚ ã€‚', 'None\n']
####PRED#### ãƒ–ãƒ­ãƒ•ã‚§ãƒ«ãƒ‰ ã® æœ€åˆ ã® ç™»å ´ ã¯ ã‚·ãƒªãƒ¼ã‚º ç¬¬äºŒä½œ ã€ ãƒ­ã‚·ã‚¢ ã‚ˆã‚Š æ„› ã‚’ ã“ã‚ ã¦ ã€ ã§ ã€ ãã® æ¬¡ ãŒ ç¬¬å››ä½œ ã€ ã‚µãƒ³ãƒ€ãƒ¼ãƒœãƒ¼ãƒ«ä½œæˆ¦ ã€ ã§ã‚ã‚‹ ã€‚	æœ€åˆ ã® ç™»å ´ ã¯; 3, 4, 5, 6 | ã‚ˆã‚Š æ„› ã‚’ ã“ã‚ ã¦; 11, 12, 13, 14, 15

list##### ['ãƒ–ãƒ­ãƒ•ã‚§ãƒ«ãƒ‰ ã® æœ€åˆ ã® ç™»å ´ ã¯ ã‚·ãƒªãƒ¼ã‚º ç¬¬äºŒä½œ ã€ ãƒ­ã‚·ã‚¢ ã‚ˆã‚Š æ„› ã‚’ ã“ã‚ ã¦ ã€ ã§ ã€ ãã® æ¬¡ ãŒ ç¬¬å››ä½œ ã€ ã‚µãƒ³ãƒ€ãƒ¼ãƒœãƒ¼ãƒ«ä½œæˆ¦ ã€ ã§ã‚ã‚‹ ã€‚', 'æœ€åˆ ã® ç™»å ´ ã¯; 3, 4, 5, 6 | ã‚ˆã‚Š æ„› ã‚’ ã“ã‚ ã¦; 11, 12, 13, 14, 15\n']
####PRED#### ã†ã©ã‚“å±‹ã•ã‚“ ã® å±‹å· ãªãŒã‚‰ ã€ è±šãƒãƒ©ä¸¼ ãŒ ãƒ¡ã‚¤ãƒ³ ã‚’ å¼µã£ ã¦ã‚‹ ã€‚	ã® å±‹å· ãªãŒã‚‰; 2, 3, 4 | ãƒ¡ã‚¤ãƒ³ ã‚’ å¼µã‚‹; 8, 9, 10 | å¼µã£ ã¦ã‚‹; 10, 11

list##### ['ã†ã©ã‚“å±‹ã•ã‚“ ã® å±‹å· ãªãŒã‚‰ ã€ è±šãƒãƒ©ä¸¼ ãŒ ãƒ¡ã‚¤ãƒ³ ã‚’ å¼µã£ ã¦ã‚‹ ã€‚', 'ã® å±‹å· ãªãŒã‚‰; 2, 3, 4 | ãƒ¡ã‚¤ãƒ³ ã‚’ å¼µã‚‹; 8, 9, 10 | å¼µã£ ã¦ã‚‹; 10, 11\n']
####PRED#### ä¸€ç‚¹ çªç ´ã— ãŸ ã‚‚ã® ãŒ ã‚ãªãŸ ã« ã‚ã‚‹ ã‹ ã€‚	ä¸€ç‚¹çªç ´ã—; 1,2

list##### ['ä¸€ç‚¹ çªç ´ã— ãŸ ã‚‚ã® ãŒ ã‚ãªãŸ ã« ã‚ã‚‹ ã‹ ã€‚', 'ä¸€ç‚¹çªç ´ã—; 1,2\n']
####PRED#### ä¸»ã« ã‚¢ãƒ€ãƒ«ãƒˆã‚²ãƒ¼ãƒ  ã‚„ ãƒ‰ãƒ©ãƒCD ã® ã‚·ãƒŠãƒªã‚ª ã‚’ æ‰‹ãŒã‘ã‚‹ ã€‚	None

list##### ['ä¸»ã« ã‚¢ãƒ€ãƒ«ãƒˆã‚²ãƒ¼ãƒ  ã‚„ ãƒ‰ãƒ©ãƒCD ã® ã‚·ãƒŠãƒªã‚ª ã‚’ æ‰‹ãŒã‘ã‚‹ ã€‚', 'None\n']
####PRED#### ç‰©å¿ƒ ã¤ã„ ãŸ ã“ã‚ ã‹ã‚‰ ã‚ã‚‹ ãŠåº— ã§ã™ ã€‚	ç‰©å¿ƒ ã¤ã„ ãŸ ã“ã‚ ã‹ã‚‰; 1, 2, 3, 4, 5

list##### ['ç‰©å¿ƒ ã¤ã„ ãŸ ã“ã‚ ã‹ã‚‰ ã‚ã‚‹ ãŠåº— ã§ã™ ã€‚', 'ç‰©å¿ƒ ã¤ã„ ãŸ ã“ã‚ ã‹ã‚‰; 1, 2, 3, 4, 5\n']
####PRED#### å¦¹ ã¯ ã€ åŒ»å­¦ç”Ÿ ã® å½¼ ãŒ ã„ã‚‹ çŸ­å¤§ç”Ÿ ã€‚	åŒ»å­¦ç”Ÿ; 4

list##### ['å¦¹ ã¯ ã€ åŒ»å­¦ç”Ÿ ã® å½¼ ãŒ ã„ã‚‹ çŸ­å¤§ç”Ÿ ã€‚', 'åŒ»å­¦ç”Ÿ; 4\n']
####PRED#### parejo ã¨ ä¼¼ ãŸ å½¢çŠ¶ ã§ã‚ã‚‹ ãŒ å…ˆç«¯ ã¨ å¸ã„å£ ã‹ã‚‰ Figurado ã® ç‰¹å¾´ ãŒ ã‚ã‚‹ ã€‚	ã¨ ä¼¼ ãŸ; 2,3,4 | å½¢çŠ¶ ã§ã‚ã‚‹; 5,6 | ã¨ å¸ã„å£ ã‹ã‚‰; 9,10,11

list##### ['parejo ã¨ ä¼¼ ãŸ å½¢çŠ¶ ã§ã‚ã‚‹ ãŒ å…ˆç«¯ ã¨ å¸ã„å£ ã‹ã‚‰ Figurado ã® ç‰¹å¾´ ãŒ ã‚ã‚‹ ã€‚', 'ã¨ ä¼¼ ãŸ; 2,3,4 | å½¢çŠ¶ ã§ã‚ã‚‹; 5,6 | ã¨ å¸ã„å£ ã‹ã‚‰; 9,10,11\n']
####PRED#### ã“ã® é–“ ã€ 552äºº ã® å’æ¥­ç”Ÿ ã‚’ è¼©å‡ºã— ãŸ ã€‚	è¼©å‡ºã—; 8

list##### ['ã“ã® é–“ ã€ 552äºº ã® å’æ¥­ç”Ÿ ã‚’ è¼©å‡ºã— ãŸ ã€‚', 'è¼©å‡ºã—; 8\n']
####PRED#### è¡—ãªã‹ ã§ åŒã˜ ã ã‘ é£Ÿã¹ ã¦ é£²ã‚“ ã ã‚‰ çµæ§‹ ãª ãŠå€¤æ®µ ã« ãªã‚‹ ã¯ãš ã€‚	é£Ÿã¹ ã¦; 5,6 | é£²ã‚“ ã ã‚‰; 7,8 | æ§‹é€  ãª; 9,10 | ãªã‚‹ ã¯ãš; 13,14

list##### ['è¡—ãªã‹ ã§ åŒã˜ ã ã‘ é£Ÿã¹ ã¦ é£²ã‚“ ã ã‚‰ çµæ§‹ ãª ãŠå€¤æ®µ ã« ãªã‚‹ ã¯ãš ã€‚', 'é£Ÿã¹ ã¦; 5,6 | é£²ã‚“ ã ã‚‰; 7,8 | æ§‹é€  ãª; 9,10 | ãªã‚‹ ã¯ãš; 13,14\n']
####PRED#### ãã‚“ãª æ—¥ã€… ã‚’ æ”¯ãˆã‚‹ ã® ã¯ ã€ å®¶æ— ã® å­˜åœ¨ ã€‚	æ”¯ãˆã‚‹ ã® ã¯; 4,5,6

list##### ['ãã‚“ãª æ—¥ã€… ã‚’ æ”¯ãˆã‚‹ ã® ã¯ ã€ å®¶æ— ã® å­˜åœ¨ ã€‚', 'æ”¯ãˆã‚‹ ã® ã¯; 4,5,6\n']
####PRED#### ã®ã¡ æ¨ªå…‰åˆ©ä¸€ ã« å¸«äº‹ã— ã€ 33å¹´ æ–‡å£‡ ã« å‡º ã¦ ã€ å¾³ç”°ç§‹å£° ã® å¨˜ ã¨ çµå©š ã€‚	å¸«äº‹ã—; 4 | å‡º ã¦; 9, 10

list##### ['ã®ã¡ æ¨ªå…‰åˆ©ä¸€ ã« å¸«äº‹ã— ã€ 33å¹´ æ–‡å£‡ ã« å‡º ã¦ ã€ å¾³ç”°ç§‹å£° ã® å¨˜ ã¨ çµå©š ã€‚', 'å¸«äº‹ã—; 4 | å‡º ã¦; 9, 10\n']
####PRED#### ã‚»ãƒ«CD ã€ DVD ã‚’ ã„ã£ã ç„¡ã ã— ã¦ ãƒ¬ãƒ³ã‚¿ãƒ« ã® å¹… ã‚’ ã‚‚ã† å°‘ã— åºƒã’ ã¦è²°ã„ ãŸã„ ã¨ã“ã‚ ã€‚	ç„¡ã ã— ã¦; 6,7,8 | ãƒ¬ãƒ³ã‚¿ãƒ« ã® å¹… ã‚’; 9,10,11,12 | ã‚‚ã† å°‘ã—; 13,14 | åºƒã’ ã¦è²°ã„ ãŸã„; 15,16,17

list##### ['ã‚»ãƒ«CD ã€ DVD ã‚’ ã„ã£ã ç„¡ã ã— ã¦ ãƒ¬ãƒ³ã‚¿ãƒ« ã® å¹… ã‚’ ã‚‚ã† å°‘ã— åºƒã’ ã¦è²°ã„ ãŸã„ ã¨ã“ã‚ ã€‚', 'ç„¡ã ã— ã¦; 6,7,8 | ãƒ¬ãƒ³ã‚¿ãƒ« ã® å¹… ã‚’; 9,10,11,12 | ã‚‚ã† å°‘ã—; 13,14 | åºƒã’ ã¦è²°ã„ ãŸã„; 15,16,17\n']
####PRED#### åŒã˜ æ–‡ç«  ã¯ ä¸Šç¥æ° ã® mixiæ—¥è¨˜ ã« ã‚‚ ã‚¢ãƒƒãƒ—ã• ã‚Œ ã¦ã„ ã¾ã™ ã€‚	ã‚¢ãƒƒãƒ—ã• ã‚Œ ã¦; 9, 10, 11

list##### ['åŒã˜ æ–‡ç«  ã¯ ä¸Šç¥æ° ã® mixiæ—¥è¨˜ ã« ã‚‚ ã‚¢ãƒƒãƒ—ã• ã‚Œ ã¦ã„ ã¾ã™ ã€‚', 'ã‚¢ãƒƒãƒ—ã• ã‚Œ ã¦; 9, 10, 11\n']
####PRED#### æ± è¢‹ ã« ã‚ã‚‹ ã‚µãƒ©ãƒªãƒ¼ãƒãƒ³ ã® å‹ ã€‚	æ± è¢‹ ã« ã‚ã‚‹; 0, 1, 2

list##### ['æ± è¢‹ ã« ã‚ã‚‹ ã‚µãƒ©ãƒªãƒ¼ãƒãƒ³ ã® å‹ ã€‚', 'æ± è¢‹ ã« ã‚ã‚‹; 0, 1, 2\n']
####PRED#### å…¬åœ’ ã« é¢ã— ãŸ ãƒ†ãƒ©ã‚¹ ãŒ å±…å¿ƒåœ° ãŒ ã‚¤ã‚¤ ã§ã™ ã€‚	å±…å¿ƒåœ°; 7 | ã‚¤ã‚¤; 9

list##### ['å…¬åœ’ ã« é¢ã— ãŸ ãƒ†ãƒ©ã‚¹ ãŒ å±…å¿ƒåœ° ãŒ ã‚¤ã‚¤ ã§ã™ ã€‚', 'å±…å¿ƒåœ°; 7 | ã‚¤ã‚¤; 9\n']
####PRED#### ç¿Œæ—¥ ã€ å…šæœ¬éƒ¨ ã‹ã‚‰ äº‹å‹™å±€ ã® å¹¹éƒ¨ ãŒ çœŒé€£ ã‚’ è¨ªã‚Œ ã¦ é™³è¬ ã€‚	è¨ªã‚Œ ã¦; 11,12

list##### ['ç¿Œæ—¥ ã€ å…šæœ¬éƒ¨ ã‹ã‚‰ äº‹å‹™å±€ ã® å¹¹éƒ¨ ãŒ çœŒé€£ ã‚’ è¨ªã‚Œ ã¦ é™³è¬ ã€‚', 'è¨ªã‚Œ ã¦; 11,12\n']
####PRED#### ã™ã”ã ãŠã‚‚ã—ã‚ã„ å ã„ ãª ã®ã§ ã€ æ°— ã« ãªã£ ãŸ äºº ã¯ æ˜¯é å—ã‘ ã¦ã‚‚ã‚‰ã„ ãŸã„ ã§ã™ ã­ ã€‚	ã™ã”ã ãŠã‚‚ã—ã‚ã„; 1, 2 | æ°— ã« ãªã£ ãŸ; 7, 8, 9, 10 | å—ã‘ ã¦ã‚‚ã‚‰ã„; 14, 15

list##### ['ã™ã”ã ãŠã‚‚ã—ã‚ã„ å ã„ ãª ã®ã§ ã€ æ°— ã« ãªã£ ãŸ äºº ã¯ æ˜¯é å—ã‘ ã¦ã‚‚ã‚‰ã„ ãŸã„ ã§ã™ ã­ ã€‚', 'ã™ã”ã ãŠã‚‚ã—ã‚ã„; 1, 2 | æ°— ã« ãªã£ ãŸ; 7, 8, 9, 10 | å—ã‘ ã¦ã‚‚ã‚‰ã„; 14, 15\n']
####PRED#### ãã‚Œ ãŒ å½“ãŸã‚Šå‰ ã€ æ™®é€š ã§ã‚ã£ ã¦ ã€ é©šã„ ãŸã‚Š ã€ å«ŒãŒã£ ãŸã‚Š ã— ãªã„ ã€‚	æ™®é€š ã§ã‚ã£ ã¦; 5,6,7 | é©šã„ ãŸã‚Š; 9,10 | å«ŒãŒã£ ãŸã‚Š; 12,13

list##### ['ãã‚Œ ãŒ å½“ãŸã‚Šå‰ ã€ æ™®é€š ã§ã‚ã£ ã¦ ã€ é©šã„ ãŸã‚Š ã€ å«ŒãŒã£ ãŸã‚Š ã— ãªã„ ã€‚', 'æ™®é€š ã§ã‚ã£ ã¦; 5,6,7 | é©šã„ ãŸã‚Š; 9,10 | å«ŒãŒã£ ãŸã‚Š; 12,13\n']
####PRED#### ä¼¼ ãŸ ã‚ˆã† ãª ã‚³ãƒ³ã‚»ãƒ—ãƒˆ ãŒ ã‚¦ã‚£ãƒªã‚¢ãƒ ãƒ»ãƒˆãƒ ã‚½ãƒ³ ã® ã‚µã‚¤ãƒ•ã‚©ãƒ³å¼ãƒ¬ã‚³ãƒ¼ãƒ€ãƒ¼ ã« ã‚‚ ã‚ã‚‰ã‚ã‚Œ ã¦ã„ã‚‹ ã€‚	ã‚ã‚‰ã‚ã‚Œ ã¦ã„ã‚‹; 12,13

list##### ['ä¼¼ ãŸ ã‚ˆã† ãª ã‚³ãƒ³ã‚»ãƒ—ãƒˆ ãŒ ã‚¦ã‚£ãƒªã‚¢ãƒ ãƒ»ãƒˆãƒ ã‚½ãƒ³ ã® ã‚µã‚¤ãƒ•ã‚©ãƒ³å¼ãƒ¬ã‚³ãƒ¼ãƒ€ãƒ¼ ã« ã‚‚ ã‚ã‚‰ã‚ã‚Œ ã¦ã„ã‚‹ ã€‚', 'ã‚ã‚‰ã‚ã‚Œ ã¦ã„ã‚‹; 12,13\n']
####PRED#### éºä½“ ã® ãã° ã« å‰ä½ã•ã‚“ ã® ã‚‚ã® ã¨ ã¿ ã‚‰ã‚Œã‚‹ æ‰‹æã’ãƒãƒƒã‚° ã¨ ç—…é™¢ ã® é§è»Šå ´ ã« è»Š ãŒ æ®‹ã• ã‚Œ ã¦ã„ ã¦ ã€ å‰ä½ã•ã‚“ ã¯ å‡ºå‹¤é€”ä¸­ ã« äº‹ä»¶ ã« é­ã£ ãŸ ã¨ ã¿ ã‚‰ã‚Œ ã¦ã„ ã¾ã™ ã€‚	å‡ºå‹¤é€”ä¸­; 27 | é­ã£ ãŸ; 31, 32 | æ®‹ã• ã‚Œ ã¦; 19, 20, 21

list##### ['éºä½“ ã® ãã° ã« å‰ä½ã•ã‚“ ã® ã‚‚ã® ã¨ ã¿ ã‚‰ã‚Œã‚‹ æ‰‹æã’ãƒãƒƒã‚° ã¨ ç—…é™¢ ã® é§è»Šå ´ ã« è»Š ãŒ æ®‹ã• ã‚Œ ã¦ã„ ã¦ ã€ å‰ä½ã•ã‚“ ã¯ å‡ºå‹¤é€”ä¸­ ã« äº‹ä»¶ ã« é­ã£ ãŸ ã¨ ã¿ ã‚‰ã‚Œ ã¦ã„ ã¾ã™ ã€‚', 'å‡ºå‹¤é€”ä¸­; 27 | é­ã£ ãŸ; 31, 32 | æ®‹ã• ã‚Œ ã¦; 19, 20, 21\n']
####PRED#### åŒºå†… ã® è¾²ä½œåœ° ã® å¤§éƒ¨åˆ† ãŒ æ°´ç”° ã§ã‚ã‚Š ã€ è¾²æ¥­ ã¯ ç¨²ä½œ ãŒ ä¸­å¿ƒ ã¨ ãªã£ ã¦ã„ã‚‹ ã€‚	ã§ã‚ã‚Š; 8 | ãªã£ ã¦ã„ã‚‹; 16, 17

list##### ['åŒºå†… ã® è¾²ä½œåœ° ã® å¤§éƒ¨åˆ† ãŒ æ°´ç”° ã§ã‚ã‚Š ã€ è¾²æ¥­ ã¯ ç¨²ä½œ ãŒ ä¸­å¿ƒ ã¨ ãªã£ ã¦ã„ã‚‹ ã€‚', 'ã§ã‚ã‚Š; 8 | ãªã£ ã¦ã„ã‚‹; 16, 17\n']
####PRED#### é£¯ç”°æ° ã¯ , â€œ ã‚ˆã‚ã—ã„ ã§ã—ã‚‡ã† ã‹ â€ ã¨ èã„ ã¦ãŠã ãªãŒã‚‰ , ã“ã¡ã‚‰ ã® è¿”äº‹ ã‚‚ å¾…ãŸ ãš ã« ä¸€æ–¹çš„ ã« é›»è©± ã‚’ åˆ‡ã£ ã¦ã—ã¾ã„ ã¾ã— ãŸ ã€‚	Okay, let's tackle this query. The user wants me to identify all multiple-word expressions (MWEs) in the given sentence. The sentence is split into words by newlines, so first I need to parse each line as a token. Let me list them out with their indices to keep track. The words are:

list##### ['é£¯ç”°æ° ã¯ , â€œ ã‚ˆã‚ã—ã„ ã§ã—ã‚‡ã† ã‹ â€ ã¨ èã„ ã¦ãŠã ãªãŒã‚‰ , ã“ã¡ã‚‰ ã® è¿”äº‹ ã‚‚ å¾…ãŸ ãš ã« ä¸€æ–¹çš„ ã« é›»è©± ã‚’ åˆ‡ã£ ã¦ã—ã¾ã„ ã¾ã— ãŸ ã€‚', "Okay, let's tackle this query. The user wants me to identify all multiple-word expressions (MWEs) in the given sentence. The sentence is split into words by newlines, so first I need to parse each line as a token. Let me list them out with their indices to keep track. The words are:\n"]
####PRED#### 1 é£¯ç”°æ°

list##### ['1 é£¯ç”°æ°\n']

Slurm Job Summary
*****************
- General information:
    date = Fri Dec 5 12:13:17 CET 2025
    hostname = nesh-gpu01
- Job information:
    JobId = 19417820
    JobName = JA_inf
    UserId = sunpn1133(820286)
    Account = sunpn1133
    QOS = normal
    NodeList = nesh-gpu01
    Features = (null)
    Command = /gxfs_work/cau/sunpn1133/parseme_2_0/job_JA_inference.sh
    WorkDir = /gxfs_work/cau/sunpn1133/parseme_2_0
    StdOut = /gxfs_work/cau/sunpn1133/parseme_2_0/test_JA.out
    StdErr = /gxfs_work/cau/sunpn1133/parseme_2_0/test_JA.err
- Requested resources:
    Timelimit = 12:30:00 ( 45000s )
    MinMemoryNode = 80G ( 81920.000M )
    NumNodes = 1
    NumCPUs = 2
    NumTasks = 1
    CPUs/Task = 2
- Used resources:
    RunTime = 03:02:23 ( 10943s )
    MaxRSS = 2373440K ( 2317.812M )
====================
- Important conclusions and remarks:
    * !!! Please, always check if the number of requested cores and nodes matches the need of your program/code !!!
    * !!! Less than 30% of requested walltime used !!! Consider adaptation of your batch script.
    * !!! Less than 10% of requested main memory used !!! Consider adaptation of your batch script.

